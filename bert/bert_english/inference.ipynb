{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T04:34:33.275369Z",
     "start_time": "2024-05-25T04:34:33.272262Z"
    }
   },
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"3\"\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "import torch\n",
    "# device = \"cpu\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "id": "ef88b12e8be83b95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T04:34:33.839838Z",
     "start_time": "2024-05-25T04:34:33.304127Z"
    }
   },
   "source": [
    "# Unpickle the pre-processed training data\n",
    "train_data_file = f\"../../data/processed_data/train_df.pkl\"\n",
    "with open(train_data_file, 'rb') as f:\n",
    "    train_df = pkl.load(f)\n",
    "\n",
    "# Unpickle the pre-processed validation data\n",
    "val_data_file = f\"../../data/processed_data/val_df.pkl\"\n",
    "with open(val_data_file, 'rb') as f:\n",
    "    val_df = pkl.load(f)"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "id": "6f170e36-77e8-4609-afa9-d39d5cafbdd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T04:34:33.843549Z",
     "start_time": "2024-05-25T04:34:33.840793Z"
    }
   },
   "source": [
    "label_number_map = {\n",
    "    \"000\":\"0\",\n",
    "    \"100\":\"1\",\n",
    "    \"101\":\"2\",\n",
    "    \"110\":\"3\",\n",
    "    \"111\":\"4\",\n",
    "}\n",
    "def new_label(hs, ag, tr):\n",
    "    if hs == 0:\n",
    "        return label_number_map.get(\"000\")\n",
    "    elif ag == 0 and tr == 0:\n",
    "        return label_number_map.get(\"100\")\n",
    "    elif ag == 0 and tr == 1:\n",
    "        return label_number_map.get(\"101\")\n",
    "    elif ag == 1 and tr == 0:\n",
    "        return label_number_map.get(\"110\")\n",
    "    elif ag == 1 and tr == 1:\n",
    "        return label_number_map.get(\"111\")\n",
    "    else:\n",
    "        raise Exception"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "id": "7636d676-8dc8-4ba4-9fe2-b21f9deaf005",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T04:34:33.945608Z",
     "start_time": "2024-05-25T04:34:33.844166Z"
    }
   },
   "source": [
    "train_df['class_label'] = train_df.apply(lambda x: new_label(x.HS, x.AG, x.TR), axis=1)\n",
    "train_df = train_df[[\"raw_text\", \"class_label\"]].rename(columns={\"raw_text\": \"body\", \"class_label\": \"target\"})\n",
    "train_df\n",
    "# train_df = train_df[:200]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                   body target\n",
       "id                                                            \n",
       "201   Hurray, saving us $$$ in so many ways @potus @...      1\n",
       "202   Why would young fighting age men be the vast m...      1\n",
       "203   @KamalaHarris Illegals Dump their Kids at the ...      1\n",
       "204   NY Times: 'Nearly All White' States Pose 'an A...      0\n",
       "205   Orban in Brussels: European leaders are ignori...      0\n",
       "...                                                 ...    ...\n",
       "9196  @mmdwriter @JRubinBlogger @BenSasse I am proud...      0\n",
       "9197  @CheriJacobus Hollywood is complicit in the ra...      0\n",
       "9198  @amaziah_filani What a fucking cunt I hate see...      4\n",
       "9199                  Hysterical woman like @CoryBooker      0\n",
       "9200  Nearly every woman I know has #meToo in their ...      0\n",
       "\n",
       "[9000 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>Hurray, saving us $$$ in so many ways @potus @...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>Why would young fighting age men be the vast m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>@KamalaHarris Illegals Dump their Kids at the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>NY Times: 'Nearly All White' States Pose 'an A...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>Orban in Brussels: European leaders are ignori...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9196</th>\n",
       "      <td>@mmdwriter @JRubinBlogger @BenSasse I am proud...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9197</th>\n",
       "      <td>@CheriJacobus Hollywood is complicit in the ra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9198</th>\n",
       "      <td>@amaziah_filani What a fucking cunt I hate see...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9199</th>\n",
       "      <td>Hysterical woman like @CoryBooker</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9200</th>\n",
       "      <td>Nearly every woman I know has #meToo in their ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9000 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "id": "9f657311-817c-430d-8e51-e30e9f96749e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T04:34:33.965719Z",
     "start_time": "2024-05-25T04:34:33.946802Z"
    }
   },
   "source": [
    "val_df['class_label'] = val_df.apply(lambda x: new_label(x.HS, x.AG, x.TR), axis=1)\n",
    "val_df = val_df[[\"raw_text\", \"class_label\"]].rename(columns={\"raw_text\": \"body\", \"class_label\": \"target\"})\n",
    "val_df\n",
    "# val_df = val_df[:20]\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                    body target\n",
       "id                                                             \n",
       "18201  I swear I’m getting to places just in the nick...      0\n",
       "18202  I’m an immigrant — and Trump is right on immig...      0\n",
       "18203  #IllegalImmigrants #IllegalAliens #ElectoralSy...      3\n",
       "18204  @DRUDGE_REPORT We have our own invasion issues...      3\n",
       "18205  Worker Charged With Sexually Molesting Eight C...      0\n",
       "...                                                  ...    ...\n",
       "19196       @SamEnvers you unfollowed me? Fuck you pussy      0\n",
       "19197  @DanReynolds STFU BITCH! AND YOU GO MAKE SOME ...      4\n",
       "19198  @2beornotbeing Honey, as a fellow white chick,...      0\n",
       "19199  I hate bitches who talk about niggaz with kids...      3\n",
       "19200  @AnnCoulter @DonaldJTrumpJr You won the\" life ...      2\n",
       "\n",
       "[1000 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18201</th>\n",
       "      <td>I swear I’m getting to places just in the nick...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18202</th>\n",
       "      <td>I’m an immigrant — and Trump is right on immig...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18203</th>\n",
       "      <td>#IllegalImmigrants #IllegalAliens #ElectoralSy...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18204</th>\n",
       "      <td>@DRUDGE_REPORT We have our own invasion issues...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18205</th>\n",
       "      <td>Worker Charged With Sexually Molesting Eight C...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19196</th>\n",
       "      <td>@SamEnvers you unfollowed me? Fuck you pussy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19197</th>\n",
       "      <td>@DanReynolds STFU BITCH! AND YOU GO MAKE SOME ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19198</th>\n",
       "      <td>@2beornotbeing Honey, as a fellow white chick,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19199</th>\n",
       "      <td>I hate bitches who talk about niggaz with kids...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19200</th>\n",
       "      <td>@AnnCoulter @DonaldJTrumpJr You won the\" life ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "id": "d35ee9c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T04:34:33.968853Z",
     "start_time": "2024-05-25T04:34:33.966403Z"
    }
   },
   "source": [
    "df_train, df_val = train_df, val_df"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "id": "34e92f56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T04:34:34.107153Z",
     "start_time": "2024-05-25T04:34:33.969605Z"
    }
   },
   "source": [
    "from transformers import AutoTokenizer\n",
    "PRE_TRAINED_MODEL_NAME = \"roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "id": "a43486da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T04:34:34.259225Z",
     "start_time": "2024-05-25T04:34:34.107962Z"
    }
   },
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "bert_model = AutoModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "\n",
    "bert_model"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaModel(\n",
       "  (embeddings): RobertaEmbeddings(\n",
       "    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): RobertaEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): RobertaPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "id": "61a8529d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T04:34:34.950281Z",
     "start_time": "2024-05-25T04:34:34.260112Z"
    }
   },
   "source": [
    "\n",
    "token_lens = []\n",
    "for txt in df_train.body:\n",
    "  tokens = tokenizer.encode(txt, max_length=128)\n",
    "  token_lens.append(len(tokens))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "id": "b3ab422f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T04:34:34.953519Z",
     "start_time": "2024-05-25T04:34:34.950924Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "MAX_LEN = np.max(token_lens)\n",
    "BATCH_SIZE = 32"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "id": "980c59ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T04:34:34.958303Z",
     "start_time": "2024-05-25T04:34:34.955098Z"
    }
   },
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SATweetDataset(Dataset):\n",
    "\n",
    "  def __init__(self, tweets, targets, tokenizer, max_len):\n",
    "    self.tweets = tweets\n",
    "    self.targets = targets\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_len = max_len\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.tweets)\n",
    "  \n",
    "  def __getitem__(self, item):\n",
    "    tweet = str(self.tweets[item])\n",
    "    target = int(self.targets[item])\n",
    "\n",
    "    encoding = self.tokenizer.encode_plus(\n",
    "      tweet,\n",
    "      add_special_tokens=True,\n",
    "      max_length=self.max_len,\n",
    "      truncation= True,\n",
    "      return_token_type_ids=False,\n",
    "      padding = 'max_length',\n",
    "      return_attention_mask=True,\n",
    "      return_tensors='pt',\n",
    "    )\n",
    "\n",
    "    return {\n",
    "      'tweet_text': tweet,\n",
    "      'input_ids': encoding['input_ids'].flatten(),\n",
    "      'attention_mask': encoding['attention_mask'].flatten(),\n",
    "      'targets': torch.tensor(target, dtype=torch.long)\n",
    "    }\n",
    "     "
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "id": "e6a72fee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T04:34:34.961252Z",
     "start_time": "2024-05-25T04:34:34.959029Z"
    }
   },
   "source": [
    "\n",
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "\n",
    "    ds = SATweetDataset(\n",
    "        tweets=df.body.to_numpy(),\n",
    "        targets=df.target.to_numpy(),\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=max_len\n",
    "    )\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=4\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "id": "be2d4a6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T04:34:34.964085Z",
     "start_time": "2024-05-25T04:34:34.961887Z"
    }
   },
   "source": [
    "\n",
    "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "id": "bc88405c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T04:34:34.967317Z",
     "start_time": "2024-05-25T04:34:34.964746Z"
    }
   },
   "source": [
    "train_data_loader"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7ebb14d9c940>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "id": "362f7c3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T04:34:35.214262Z",
     "start_time": "2024-05-25T04:34:34.968298Z"
    }
   },
   "source": [
    "\n",
    "data = next(iter(train_data_loader))\n",
    "data.keys()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['tweet_text', 'input_ids', 'attention_mask', 'targets'])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "id": "b04205f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T04:34:35.218356Z",
     "start_time": "2024-05-25T04:34:35.215488Z"
    }
   },
   "source": [
    "\n",
    "n_classes = 5\n",
    "class_names = ['1', '2', '3', '4', '5']\n",
    "PRE_TRAINED_MODEL_NAME = \"roberta-base\"\n",
    "WEIGHTS_PATH = \"roberta_weights.bin\"\n",
    "n_classes = 5"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "id": "17ee6230",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T04:34:35.222490Z",
     "start_time": "2024-05-25T04:34:35.219505Z"
    }
   },
   "source": [
    "\n",
    "input_ids = data['input_ids']\n",
    "attention_mask = data['attention_mask']\n",
    "\n",
    "print(input_ids.shape) # batch size x seq length\n",
    "print(attention_mask.shape) # batch size x seq length"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "id": "ca5b854b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T04:34:35.226950Z",
     "start_time": "2024-05-25T04:34:35.223253Z"
    }
   },
   "source": [
    "from torch import nn, optim\n",
    "\n",
    "class SentimentClassifier(nn.Module):\n",
    "\n",
    "  def __init__(self, n_classes):\n",
    "    super(SentimentClassifier, self).__init__()\n",
    "    #importing the pre_trained model from transformers library\n",
    "    self.bert = bert_model.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "    #Adding a linear layer on the top of the bert model\n",
    "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "  #The forward step function\n",
    "  def forward(self, input_ids, attention_mask):\n",
    "    _, pooled_output = self.bert(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask,\n",
    "      return_dict=False\n",
    "    )\n",
    "    output = pooled_output\n",
    "    return self.out(output)"
   ],
   "outputs": [],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "id": "e3ac90a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T04:34:35.482193Z",
     "start_time": "2024-05-25T04:34:35.227800Z"
    }
   },
   "source": [
    "model = SentimentClassifier(n_classes)\n",
    "model.cpu()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SentimentClassifier(\n",
       "  (bert): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (out): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "id": "a745410d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T04:34:35.697961Z",
     "start_time": "2024-05-25T04:34:35.482961Z"
    }
   },
   "source": "model.load_state_dict(torch.load(WEIGHTS_PATH, map_location=\"cpu\"))",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "id": "312b07f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T04:34:35.702338Z",
     "start_time": "2024-05-25T04:34:35.698918Z"
    }
   },
   "source": [
    "def eval_model(model, data_loader, loss_fn, n_examples):\n",
    "  model = model.eval()\n",
    "\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "  all_preds, all_targets = [], []\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for d in data_loader:\n",
    "      input_ids = d[\"input_ids\"]\n",
    "      attention_mask = d[\"attention_mask\"]\n",
    "      targets = d[\"targets\"]\n",
    "\n",
    "      outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask\n",
    "      )\n",
    "      _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "      loss = loss_fn(outputs, targets)\n",
    "\n",
    "      correct_predictions += torch.sum(preds == targets)\n",
    "      losses.append(loss.item())\n",
    "      all_preds.append(preds)\n",
    "      all_targets.append(targets)\n",
    "\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses), all_preds, all_targets"
   ],
   "outputs": [],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "id": "406b8501",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T04:39:17.458568Z",
     "start_time": "2024-05-25T04:34:35.703530Z"
    }
   },
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "val_acc, val_loss, preds, targets = eval_model(\n",
    "    model,\n",
    "    val_data_loader,\n",
    "    loss_fn, \n",
    "    len(df_val)\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "id": "4355c942",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T04:39:17.463197Z",
     "start_time": "2024-05-25T04:39:17.459696Z"
    }
   },
   "source": [
    "val_acc"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6650, dtype=torch.float64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "id": "c3a3f320",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T04:39:17.467838Z",
     "start_time": "2024-05-25T04:39:17.464212Z"
    }
   },
   "source": [
    "len(preds), len(preds[0])"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "id": "24ff4c29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T04:39:17.471763Z",
     "start_time": "2024-05-25T04:39:17.468681Z"
    }
   },
   "source": [
    "len(targets)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "id": "b208419c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T04:39:17.475466Z",
     "start_time": "2024-05-25T04:39:17.472491Z"
    }
   },
   "source": [
    "len(val_df)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "id": "6600de2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T04:39:17.481332Z",
     "start_time": "2024-05-25T04:39:17.476583Z"
    }
   },
   "source": [
    "prediction_vals, target_vals = [], []\n",
    "for tensor in preds:\n",
    "    for val in tensor:\n",
    "        prediction_vals.append(val.item())\n",
    "for tensor in targets:\n",
    "    for val in tensor:\n",
    "        target_vals.append(val.item())\n",
    "\n",
    "prediction_list, target_list = prediction_vals[:len(val_df)], target_vals[:len(val_df)]\n",
    "        "
   ],
   "outputs": [],
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "id": "eba058da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T04:39:17.485722Z",
     "start_time": "2024-05-25T04:39:17.482563Z"
    }
   },
   "source": [
    "match, miss = 0,0\n",
    "for prediction, target in zip(prediction_list, target_list):\n",
    "    if prediction == target:\n",
    "        match+=1\n",
    "    else:\n",
    "        miss+=1"
   ],
   "outputs": [],
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "id": "b0a0e21a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T04:39:17.490430Z",
     "start_time": "2024-05-25T04:39:17.488058Z"
    }
   },
   "source": [
    "match, miss"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(665, 335)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "id": "38bbdbb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T04:39:17.684133Z",
     "start_time": "2024-05-25T04:39:17.491023Z"
    }
   },
   "source": "torch.cuda_is_available()",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'cuda_is_available'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[55], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda_is_available\u001B[49m()\n",
      "File \u001B[0;32m~/miniconda3/envs/Affect/lib/python3.9/site-packages/torch/__init__.py:1833\u001B[0m, in \u001B[0;36m__getattr__\u001B[0;34m(name)\u001B[0m\n\u001B[1;32m   1830\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mimportlib\u001B[39;00m\n\u001B[1;32m   1831\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m importlib\u001B[38;5;241m.\u001B[39mimport_module(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;18m__name__\u001B[39m)\n\u001B[0;32m-> 1833\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodule \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'torch' has no attribute 'cuda_is_available'"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "id": "b231ea6a",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1d6f7499",
   "metadata": {},
   "source": "os.environ",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e2062ef2",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ea96deb3",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "812a93cf",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c103651e",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
